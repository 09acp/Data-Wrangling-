{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- S. Jansen Datacamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  select sub-periods from a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe prices here\n",
    "prices = pd.DataFrame()\n",
    "\n",
    "# Select data for each year and concatenate with prices here \n",
    "for year in [\"2013\", \"2014\", \"2015\"]:\n",
    "    price_per_year = yahoo.loc[year, [\"price\"]].reset_index(drop=True)\n",
    "    price_per_year.rename(columns={\"price\": year}, inplace=True)\n",
    "    prices = pd.concat([prices, price_per_year], axis=1)\n",
    "\n",
    "# Plot prices\n",
    "prices.info()\n",
    "prices.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting stock prices across time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "google = pd.read_csv(\"google.csv\", parse_dates =[\"Date\"], index_col=\"Date\")\n",
    "google.head()\n",
    "\n",
    "# Set data frequency to business daily\n",
    "google = google.asfreq(\"B\")\n",
    "\n",
    "# Create 'lagged' and 'shifted'\n",
    "google['lagged'] = google.Close.shift(-90)\n",
    "google['shifted'] = google.Close.shift(90)\n",
    "\n",
    "# Plot the google price series\n",
    "google.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## absolute changes from current and shifted prices,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Created shifted_30 here\n",
    "yahoo['shifted_30'] = yahoo.price.shift(30)\n",
    "\n",
    "# Subtract shifted_30 from price\n",
    "yahoo['change_30'] = yahoo.price.sub(yahoo.shifted_30)\n",
    "\n",
    "# Get the 30-day price difference\n",
    "yahoo['diff_30'] = yahoo['price'].diff(periods=30)\n",
    "\n",
    "# Inspect the last five rows of price\n",
    "print(yahoo.tail())\n",
    "\n",
    "# Show the value_counts of the difference between change_30 and diff_30\n",
    "print( yahoo.change_30.sub(yahoo.diff_30).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting multi-period returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create daily_return\n",
    "google['daily_return'] = google.Close.pct_change(periods=1)*100\n",
    "\n",
    "# Create monthly_return\n",
    "google['monthly_return'] = google.Close.pct_change(periods=30)*100\n",
    "\n",
    "# Create annual_return\n",
    "google['annual_return'] = google.Close.pct_change(periods=360)*100\n",
    "\n",
    "# Plot the result\n",
    "google.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## easily compare several time series by normalizing their starting points to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "prices = pd.read_csv(\"asset_classes.csv\",parse_dates=[\"DATE\"],index_col=\"DATE\")\n",
    "\n",
    "# Inspect prices here\n",
    "print(prices.info())\n",
    "\n",
    "# Select first prices\n",
    "first_prices = prices.iloc[0]\n",
    "first_prices\n",
    "\n",
    "# Create normalized\n",
    "normalized = prices.div(first_prices).mul(100)\n",
    "\n",
    "# Plot normalized\n",
    "normalized.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2, 'Basic Time Series Metrics & Resampling'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare the performance of various stocks against a benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stock prices and index here\n",
    "stocks = pd.read_csv(\"nyse.csv\",parse_dates=[\"date\"],index_col=\"date\")\n",
    "dow_jones = pd.read_csv(\"dow_jones.csv\",parse_dates=[\"date\"],index_col=\"date\")\n",
    "\n",
    "# Concatenate data and inspect result here\n",
    "data = pd.concat([stocks,dow_jones],axis=1)\n",
    "print(data.info())\n",
    "\n",
    "# Normalize and plot your data here\n",
    "data.div(data.iloc[0]).mul(100).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot performance difference vs benchmark index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tickers\n",
    "tickers = [\"MSFT\",\"AAPL\"]\n",
    "\n",
    "# Import stock data here\n",
    "stocks = pd.read_csv(\"msft_aapl.csv\",parse_dates=[\"date\"],index_col=\"date\")\n",
    "\n",
    "# Import index here\n",
    "sp500 = pd.read_csv(\"sp500.csv\",parse_dates=[\"date\"],index_col=\"date\")\n",
    "\n",
    "# Concatenate stocks and index here\n",
    "data = pd.concat([stocks,sp500],axis=1).dropna()\n",
    "# Normalize data\n",
    "normalized = data.div(data.iloc[0]).mul(100)\n",
    "\n",
    "# Subtract the normalized index from the normalized stock prices, and plot the result\n",
    "(normalized[tickers].sub(normalized[\"SP500\"], axis=0)).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert monthly to weekly data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start and end dates\n",
    "start = '2016-1-1'\n",
    "end = '2016-2-29'\n",
    "\n",
    "# Create monthly_dates here\n",
    "monthly_dates = pd.date_range(start=start, end=end, freq='M')\n",
    "\n",
    "# Create monthly here\n",
    "monthly = pd.Series(data=[1,2], index=monthly_dates)\n",
    "print(monthly)\n",
    "\n",
    "# Create weekly_dates here\n",
    "weekly_dates = pd.date_range(start=start, end=end, freq='W')\n",
    "\n",
    "# Print monthly, reindexed using weekly_dates\n",
    "print(monthly.reindex(weekly_dates))\n",
    "print(monthly.reindex(weekly_dates, method='bfill'))\n",
    "print(monthly.reindex(weekly_dates, method='ffill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create weekly from monthly unemployment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "data = pd.read_csv('unemployment.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Show first five rows of weekly series\n",
    "print(data.asfreq('W').head())\n",
    "\n",
    "# Show first five rows of weekly series with bfill option\n",
    "print(data.asfreq('W', method='bfill').head())\n",
    "\n",
    "# Create weekly series with ffill option and show first five rows\n",
    "weekly_ffill = data.asfreq('W', method='ffill')\n",
    "print(weekly_ffill.head())\n",
    "\n",
    "# Plot weekly_fill starting 2015 here \n",
    "weekly_ffill.loc['2015':].plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use interpolation to create weekly employment data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data here\n",
    "print(monthly.info())\n",
    "\n",
    "# Create weekly dates\n",
    "weekly_dates = pd.date_range(monthly.index.min(), monthly.index.max(), freq='W')\n",
    "\n",
    "# Reindex monthly to weekly data\n",
    "weekly = monthly.reindex(weekly_dates)\n",
    "\n",
    "# Create ffill and interpolated columns\n",
    "weekly['ffill'] = weekly.UNRATE.ffill()\n",
    "weekly['interpolated'] = weekly.UNRATE.interpolate()\n",
    "\n",
    "# Plot weekly\n",
    "weekly.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate debt/GDP and compare to unemployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import & inspect data here\n",
    "data = pd.read_csv('debt_unemployment.csv', parse_dates=[\"date\"],index_col=\"date\")\n",
    "print(data.info())\n",
    "\n",
    "# Interpolate and inspect here\n",
    "interpolated = data.interpolate()\n",
    "print(interpolated.info())\n",
    "\n",
    "# Plot interpolated data here\n",
    "interpolated.plot(secondary_y= \"Unemployment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare weekly, monthly and annual ozone trends for NYC & LA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect data here\n",
    "ozone = pd.read_csv('ozone.csv', parse_dates=[\"date\"],index_col=\"date\")\n",
    "print(ozone.info())\n",
    "\n",
    "# Calculate and plot the weekly average ozone trend\n",
    "ozone.resample(\"W\").mean().plot()\n",
    "plt.show()\n",
    "# Calculate and plot the monthly average ozone trend\n",
    "ozone.resample(\"M\").mean().plot()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the annual average ozone trend\n",
    "ozone.resample(\"A\").mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare monthly average stock prices for Facebook and Google\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect data here\n",
    "stocks = pd.read_csv('stocks.csv', parse_dates=[\"date\"],index_col=\"date\")\n",
    "print(stocks.info())\n",
    "\n",
    "# Calculate and plot the monthly averages\n",
    "monthly_average = stocks.resample(\"M\").mean()\n",
    "monthly_average.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare quarterly GDP growth rate and stock returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect gdp_growth here\n",
    "gdp_growth = pd.read_csv('gdp_growth.csv', parse_dates=[\"date\"],index_col=\"date\")\n",
    "print(gdp_growth.info())\n",
    "\n",
    "\n",
    "# Import and inspect djia here\n",
    "djia = pd.read_csv(\"djia.csv\",parse_dates=[\"date\"],index_col=\"date\")\n",
    "print(djia.info())\n",
    "\n",
    "# Calculate djia quarterly returns here \n",
    "djia_quarterly = djia.resample(\"QS\").first()\n",
    "djia_quarterly_return = djia_quarterly.pct_change().mul(100)\n",
    "\n",
    "# Concatenate, rename and plot djia_quarterly_return and gdp_growth here \n",
    "data = pd.concat([gdp_growth,djia_quarterly_return],axis=1)\n",
    "data.columns = [\"gdp\",\"djia\"]\n",
    "data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize monthly mean, median and standard deviation of S&P500 returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "sp500 = pd.read_csv(\"sp500.csv\",parse_dates=[\"date\"],index_col=\"date\")\n",
    "sp500.head()\n",
    "\n",
    "# Calculate daily returns here\n",
    "daily_returns = sp500.squeeze().pct_change()\n",
    "daily_returns.head()\n",
    "# Resample and calculate statistics\n",
    "stats = daily_returns.resample(\"M\").agg([\"mean\",\"median\",\"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Window Functions: Rolling & Expanding Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rolling average air quality since 2010 for new york city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect ozone data here\n",
    "data = pd.read_csv(\"ozone.csv\",parse_dates=[\"date\"],index_col=[\"date\"])\n",
    "print(data.info())\n",
    "\n",
    "# Calculate 90d and 360d rolling mean for the last price\n",
    "data['90D'] = data.Ozone.rolling(\"90D\").mean()\n",
    "data['360D'] = data.Ozone.rolling(\"360D\").mean()\n",
    "\n",
    "# Plot data\n",
    "data.loc[\"2010\":].plot()\n",
    "plt.title(\"New York City\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rolling 360-day median & std. deviation for nyc ozone data since 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect ozone data here\n",
    "data = pd.read_csv(\"ozone.csv\",parse_dates=[\"date\"],index_col=\"date\").dropna()\n",
    "print(data.info())\n",
    "\n",
    "# Calculate the rolling mean and std here\n",
    "rolling_stats = data.Ozone.rolling(360).agg([\"mean\",\"std\"])\n",
    "\n",
    "# Join rolling_stats with ozone data\n",
    "stats = data.join(rolling_stats)\n",
    "\n",
    "# Plot stats\n",
    "stats.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rolling quantiles for daily air quality in nyc\n",
    "\n",
    "changes in the dispersion of a time series over time in a way that is less sensitive to outliers than using the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample, interpolate and inspect ozone data here\n",
    "data = data.resample(\"D\").interpolate()\n",
    "print (data.info())\n",
    "# Create the rolling window\n",
    "rolling = data.Ozone.rolling(360)\n",
    "\n",
    "# Insert the rolling quantiles to the monthly returns\n",
    "data['q10'] = rolling.quantile(.1).to_frame(\"Q10\")\n",
    "data['q50'] = rolling.quantile(.5).to_frame(\"Q50\")\n",
    "data['q90'] = rolling.quantile(.9).to_frame(\"Q90\")\n",
    "\n",
    "# Plot monthly returns\n",
    "data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding window functions with pandas\n",
    "- Cumulative sum vs .diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate differences\n",
    "differences = data.diff().dropna()\n",
    "differences.head()\n",
    "# Select start price\n",
    "start_price = data.first(\"D\")\n",
    "\n",
    "# Calculate cumulative sum\n",
    "cumulative_sum = start_price.append(differences).cumsum()\n",
    "\n",
    "# Validate cumulative sum equals data\n",
    "print(data.equals(cumulative_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cumulative return on $1,000 invested in google vs apple I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your investment\n",
    "investment = 1000\n",
    "\n",
    "# Calculate the daily returns here\n",
    "returns = data.pct_change()\n",
    "\n",
    "# Calculate the cumulative returns here\n",
    "returns_plus_one = returns+1\n",
    "cumulative_return = returns_plus_one.cumprod()\n",
    "\n",
    "z = data.pct_change().add(1).cumprod()\n",
    "z.equals(cumulative_return)\n",
    "\n",
    "\n",
    "# Calculate and plot the investment return here \n",
    "cumulative_return.mul(investment).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rolling yearly returns on $1,000 invested in google vs apple II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Define a multi_period_return function\n",
    "def multi_period_return(period_returns):\n",
    "    return np.prod(period_returns+1)-1\n",
    "    \n",
    "# Calculate daily returns\n",
    "daily_returns = data.pct_change()\n",
    "\n",
    "# Calculate rolling_annual_returns\n",
    "rolling_annual_returns = daily_returns.rolling(\"360D\").apply(multi_period_return).mul(100)\n",
    "# Plot rolling_annual_returns\n",
    "rolling_annual_returns.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a random walk of returns by sampling from actual returns, and how to use this random sample to create a random stock price path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed here\n",
    "seed = 42\n",
    "\n",
    "# Create random_walk\n",
    "random_walk = normal(loc=0.001,scale=0.01,size=2500)\n",
    "\n",
    "# Convert random_walk to pd.series\n",
    "random_walk = pd.Series(random_walk)\n",
    "\n",
    "# Create random_prices\n",
    "random_prices = random_walk.add(1).cumprod()\n",
    "\n",
    "# Plot random_prices here\n",
    "random_prices.mul(1000).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- build a random walk using historical returns from Facebook's stock price since IPO through the end of May 31, 2017. Then you'll simulate an alternative random price path in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed here\n",
    "seed = 42\n",
    "\n",
    "# Calculate daily_returns here\n",
    "daily_returns = fb.pct_change().dropna()\n",
    "# Get n_obs\n",
    "n_obs = daily_returns.count()\n",
    "# Create random_walk\n",
    "random_walk = choice(daily_returns,size=n_obs)\n",
    "# Convert random_walk to pd.series\n",
    "random_walk = pd.Series(random_walk)\n",
    "# Plot random_walk distribution\n",
    "sns.distplot(random_walk)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- random sample of returns like the one you've generated during the last exercise and use it to create a random stock price path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select fb start price here\n",
    "start = fb.price.first('D')\n",
    "\n",
    "# Add 1 to random walk and append to start\n",
    "random_walk = random_walk.add(1)\n",
    "random_price = start.append(random_walk)\n",
    "\n",
    "# Calculate cumulative product here\n",
    "random_price = random_price.cumprod()\n",
    "\n",
    "# Insert into fb and plot\n",
    "fb['random'] = random_price\n",
    "fb.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships between time series: correlation\n",
    "- Relationships between time series: correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Annual return correlations among several stocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data here\n",
    "print(data.info())\n",
    "\n",
    "# Calculate year-end prices here\n",
    "annual_prices = data.resample(\"A\").last()\n",
    "\n",
    "# Calculate annual returns here\n",
    "annual_returns = annual_prices.pct_change()\n",
    "\n",
    "# Calculate and print the correlation matrix here\n",
    "correlations = annual_returns.corr()\n",
    "print(correlations)\n",
    "\n",
    "# Visualize the correlations as heatmap here\n",
    "sns.heatmap(correlations, annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------- END OF TAUGHT COURSE -------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
